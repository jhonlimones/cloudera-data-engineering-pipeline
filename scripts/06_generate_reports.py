"""
FASE 6: GENERACI√ìN DE REPORTES
Consolida resultados y genera reportes ejecutivos
"""
import logging
import sys
import json
from datetime import datetime
from pathlib import Path

sys.path.append('..')
from utils import create_spark_session, stop_spark_session
from utils.constants import (
    PROCESSED_DATA_PATH, FRAUD_ALERTS_PATH, 
    ANALYTICS_PATH, REPORTS_PATH, LOGS_DIR
)

# Configurar logging
log_file = LOGS_DIR / f"06_reports_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(log_file),
        logging.StreamHandler()
    ]
)

def load_analytics_results():
    """Carga resultados de las queries anal√≠ticas"""
    json_file = ANALYTICS_PATH / "analytics_results.json"
    
    if not json_file.exists():
        logging.warning("‚ö†Ô∏è No se encontraron resultados anal√≠ticos")
        return None
    
    with open(json_file, 'r', encoding='utf-8') as f:
        return json.load(f)

def generate_executive_summary(spark):
    """Genera resumen ejecutivo"""
    logging.info("Generando resumen ejecutivo...")
    
    # Leer datos
    df = spark.read.parquet(str(PROCESSED_DATA_PATH))
    
    # Calcular m√©tricas clave
    total_transactions = df.count()
    approved = df.filter(df.status == 'APPROVED').count()
    declined = df.filter(df.status == 'DECLINED').count()
    fraud = df.filter(df.status == 'FRAUD').count()
    pending = df.filter(df.status == 'PENDING').count()
    
    total_amount = df.agg({'amount': 'sum'}).collect()[0][0]
    avg_amount = df.agg({'amount': 'avg'}).collect()[0][0]
    unique_customers = df.select('customer_id').distinct().count()
    
    # Alertas de fraude
    fraud_alerts_file = FRAUD_ALERTS_PATH / "fraud_alerts.parquet"
    fraud_alerts_count = 0
    if fraud_alerts_file.exists():
        df_fraud = spark.read.parquet(str(fraud_alerts_file))
        fraud_alerts_count = df_fraud.count()
    
    summary = {
        'fecha_generacion': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        'periodo_analizado': '2025-10-01 a 2025-10-14',
        'metricas_generales': {
            'total_transacciones': total_transactions,
            'clientes_unicos': unique_customers,
            'monto_total': round(total_amount, 2),
            'monto_promedio': round(avg_amount, 2)
        },
        'distribucion_estados': {
            'aprobadas': approved,
            'rechazadas': declined,
            'fraude': fraud,
            'pendientes': pending,
            'tasa_aprobacion': round(approved * 100.0 / total_transactions, 2)
        },
        'alertas_fraude': {
            'total_alertas': fraud_alerts_count,
            'tasa_deteccion': round(fraud_alerts_count * 100.0 / total_transactions, 2)
        }
    }
    
    return summary

def generate_markdown_report(summary, analytics_results):
    """Genera reporte en formato Markdown"""
    logging.info("Generando reporte Markdown...")
    
    report = f"""# üìä REPORTE DE AN√ÅLISIS BANCARIO
## Pipeline Cloudera Data Engineering

**Fecha de generaci√≥n:** {summary['fecha_generacion']}  
**Per√≠odo analizado:** {summary['periodo_analizado']}

---

## üìà RESUMEN EJECUTIVO

### M√©tricas Generales
- **Total de transacciones procesadas:** {summary['metricas_generales']['total_transacciones']:,}
- **Clientes √∫nicos:** {summary['metricas_generales']['clientes_unicos']:,}
- **Monto total procesado:** ‚Ç¨{summary['metricas_generales']['monto_total']:,.2f}
- **Monto promedio por transacci√≥n:** ‚Ç¨{summary['metricas_generales']['monto_promedio']:.2f}

### Distribuci√≥n de Estados
| Estado | Cantidad | Porcentaje |
|--------|----------|------------|
| ‚úÖ Aprobadas | {summary['distribucion_estados']['aprobadas']:,} | {summary['distribucion_estados']['tasa_aprobacion']}% |
| ‚ùå Rechazadas | {summary['distribucion_estados']['rechazadas']:,} | {round(summary['distribucion_estados']['rechazadas'] * 100.0 / summary['metricas_generales']['total_transacciones'], 2)}% |
| ‚ö†Ô∏è Fraude | {summary['distribucion_estados']['fraude']:,} | {round(summary['distribucion_estados']['fraude'] * 100.0 / summary['metricas_generales']['total_transacciones'], 2)}% |
| üïê Pendientes | {summary['distribucion_estados']['pendientes']:,} | {round(summary['distribucion_estados']['pendientes'] * 100.0 / summary['metricas_generales']['total_transacciones'], 2)}% |

### üö® Alertas de Fraude
- **Total de alertas detectadas:** {summary['alertas_fraude']['total_alertas']}
- **Tasa de detecci√≥n:** {summary['alertas_fraude']['tasa_deteccion']}%

---

## üåç AN√ÅLISIS POR PA√çS

"""
    
    # Agregar an√°lisis por pa√≠s si existe
    if analytics_results and 'by_country' in analytics_results:
        report += "| Pa√≠s | Transacciones | Monto Total | Monto Promedio | Tasa Aprobaci√≥n |\n"
        report += "|------|---------------|-------------|----------------|------------------|\n"
        for row in analytics_results['by_country'][:10]:
            report += f"| {row['country']} | {row['total_transactions']:,} | ‚Ç¨{row['total_amount']:,.2f} | ‚Ç¨{row['avg_amount']:.2f} | {row['approval_rate']}% |\n"
    
    report += "\n---\n\n## üí≥ AN√ÅLISIS POR CATEGOR√çA\n\n"
    
    if analytics_results and 'by_category' in analytics_results:
        report += "| Categor√≠a | Transacciones | Monto Total | Porcentaje |\n"
        report += "|-----------|---------------|-------------|------------|\n"
        for row in analytics_results['by_category']:
            report += f"| {row['category']} | {row['total_transactions']:,} | ‚Ç¨{row['total_amount']:,.2f} | {row['percentage']}% |\n"
    
    report += "\n---\n\n## üïê AN√ÅLISIS TEMPORAL\n\n"
    
    if analytics_results and 'by_time_slot' in analytics_results:
        report += "| Franja Horaria | Transacciones | Monto Total | Rechazadas |\n"
        report += "|----------------|---------------|-------------|------------|\n"
        for row in analytics_results['by_time_slot']:
            report += f"| {row['time_slot']} | {row['total_transactions']:,} | ‚Ç¨{row['total_amount']:,.2f} | {row['declined_count']} |\n"
    
    report += f"""

---

## üîß ARQUITECTURA T√âCNICA

### Pipeline Implementado
1. **Ingesta y Validaci√≥n** - Lectura desde "HDFS" (data/raw)
2. **Transformaci√≥n** - Feature engineering con PySpark
3. **Detecci√≥n de Fraude** - Aplicaci√≥n de reglas de negocio
4. **Capa Hive/Impala** - Tablas externas sobre Parquet
5. **Queries Anal√≠ticas** - Spark SQL para an√°lisis
6. **Reportes** - Generaci√≥n automatizada

### Tecnolog√≠as Utilizadas
- **Apache Spark** - Procesamiento distribuido
- **Parquet** - Almacenamiento columnar comprimido
- **Spark SQL** - Queries anal√≠ticas (simula Hive/Impala)
- **Python/PySpark** - Lenguaje de desarrollo

### Formatos de Datos
- **Input:** CSV (raw data)
- **Processing:** Parquet particionado por fecha
- **Output:** Parquet, JSON, CSV (reportes)

---

## üìù CONCLUSIONES

1. Se procesaron exitosamente {summary['metricas_generales']['total_transacciones']:,} transacciones
2. Tasa de aprobaci√≥n: **{summary['distribucion_estados']['tasa_aprobacion']}%**
3. Se detectaron **{summary['alertas_fraude']['total_alertas']} alertas** de posible fraude
4. El pipeline es escalable y replicable en entorno Cloudera real

---

**Generado por:** Cloudera Data Engineering Pipeline  
**Fecha:** {summary['fecha_generacion']}
"""
    
    return report

def generate_text_report(summary):
    """Genera reporte en texto plano"""
    logging.info("Generando reporte de texto...")
    
    report = f"""
{'='*80}
REPORTE DE AN√ÅLISIS BANCARIO - PIPELINE CLOUDERA DATA ENGINEERING
{'='*80}

Fecha de generaci√≥n: {summary['fecha_generacion']}
Per√≠odo analizado: {summary['periodo_analizado']}

{'='*80}
RESUMEN EJECUTIVO
{'='*80}

M√âTRICAS GENERALES:
  - Total transacciones procesadas: {summary['metricas_generales']['total_transacciones']:,}
  - Clientes √∫nicos: {summary['metricas_generales']['clientes_unicos']:,}
  - Monto total procesado: ‚Ç¨{summary['metricas_generales']['monto_total']:,.2f}
  - Monto promedio: ‚Ç¨{summary['metricas_generales']['monto_promedio']:.2f}

DISTRIBUCI√ìN DE ESTADOS:
  - Aprobadas: {summary['distribucion_estados']['aprobadas']:,} ({summary['distribucion_estados']['tasa_aprobacion']}%)
  - Rechazadas: {summary['distribucion_estados']['rechazadas']:,}
  - Fraude: {summary['distribucion_estados']['fraude']:,}
  - Pendientes: {summary['distribucion_estados']['pendientes']:,}

ALERTAS DE FRAUDE:
  - Total alertas detectadas: {summary['alertas_fraude']['total_alertas']}
  - Tasa de detecci√≥n: {summary['alertas_fraude']['tasa_deteccion']}%

{'='*80}
PIPELINE EJECUTADO EXITOSAMENTE
{'='*80}

Fases completadas:
  ‚úÖ Fase 1: Ingesta y validaci√≥n
  ‚úÖ Fase 2: Transformaci√≥n y enriquecimiento
  ‚úÖ Fase 3: Detecci√≥n de anomal√≠as
  ‚úÖ Fase 4: Creaci√≥n de tablas Hive/Impala
  ‚úÖ Fase 5: Queries anal√≠ticas
  ‚úÖ Fase 6: Generaci√≥n de reportes

{'='*80}
"""
    return report

def main():
    """Funci√≥n principal de generaci√≥n de reportes"""
    logging.info("=" * 70)
    logging.info("INICIANDO FASE 6: GENERACI√ìN DE REPORTES")
    logging.info("=" * 70)
    
    spark = None
    
    try:
        spark = create_spark_session("06_GenerateReports")
        
        # Generar resumen ejecutivo
        summary = generate_executive_summary(spark)
        
        # Cargar resultados anal√≠ticos
        analytics_results = load_analytics_results()
        
        # Generar reporte Markdown
        markdown_report = generate_markdown_report(summary, analytics_results)
        markdown_file = REPORTS_PATH / f"report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
        
        with open(markdown_file, 'w', encoding='utf-8') as f:
            f.write(markdown_report)
        
        logging.info(f"‚úÖ Reporte Markdown guardado: {markdown_file}")
        
        # Generar reporte de texto
        text_report = generate_text_report(summary)
        text_file = REPORTS_PATH / f"report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
        
        with open(text_file, 'w', encoding='utf-8') as f:
            f.write(text_report)
        
        logging.info(f"‚úÖ Reporte de texto guardado: {text_file}")
        
        # Guardar resumen en JSON
        json_file = REPORTS_PATH / f"summary_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(summary, f, indent=2, ensure_ascii=False)
        
        logging.info(f"‚úÖ Resumen JSON guardado: {json_file}")
        
        # Mostrar resumen en consola
        logging.info("\n" + text_report)
        
        logging.info("\n" + "=" * 70)
        logging.info("REPORTES GENERADOS")
        logging.info("=" * 70)
        logging.info(f"üìÑ Markdown: {markdown_file}")
        logging.info(f"üìÑ Texto: {text_file}")
        logging.info(f"üìÑ JSON: {json_file}")
        logging.info("=" * 70)
        
        logging.info("‚úÖ FASE 6 COMPLETADA EXITOSAMENTE")
        
        return 0
        
    except Exception as e:
        logging.error(f"‚ùå Error generando reportes: {str(e)}", exc_info=True)
        return 1
        
    finally:
        if spark:
            stop_spark_session(spark)

if __name__ == "__main__":
    sys.exit(main())