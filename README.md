## ğŸ—ï¸ Arquitectura del Pipeline
```mermaid
graph LR
    A[ğŸ“„ CSV Raw Data<br/>2000 transacciones] --> B[ğŸ” Fase 1: Ingesta<br/>ValidaciÃ³n + Limpieza<br/>PySpark]
    B --> C[âš™ï¸ Fase 2: TransformaciÃ³n<br/>Feature Engineering<br/>Window Functions]
    C --> D[ğŸš¨ Fase 3: DetecciÃ³n Fraude<br/>Reglas de Negocio<br/>Risk Score]
    D --> E[ğŸ—„ï¸ Fase 4: Tablas Hive<br/>Parquet Particionado<br/>HDFS Simulado]
    E --> F[ğŸ“Š Fase 5: Queries SQL<br/>Spark SQL<br/>10 AnÃ¡lisis]
    F --> G[ğŸ“‹ Fase 6: Reportes<br/>Markdown + JSON + TXT]
    
    style A fill:#e1f5ff
    style B fill:#fff4e1
    style C fill:#ffe1f5
    style D fill:#ffe1e1
    style E fill:#e1ffe1
    style F fill:#f5e1ff
    style G fill:#e1ffff
```

### **Flujo Detallado**

| Fase | TecnologÃ­a | Input | Output | Tiempo |
|------|------------|-------|--------|--------|
| **1ï¸âƒ£ Ingesta** | PySpark + Validators | `transactions.csv` | `transactions_validated.parquet` | ~6s |
| **2ï¸âƒ£ TransformaciÃ³n** | PySpark + Window Functions | Parquet validado | Parquet particionado (aÃ±o/mes/dÃ­a) | ~5s |
| **3ï¸âƒ£ DetecciÃ³n Fraude** | Reglas de negocio | Datos transformados | `fraud_alerts.parquet` + CSV | ~3s |
| **4ï¸âƒ£ Tablas Hive** | Spark SQL | Parquet procesado | Tablas SQL + DDL | ~2s |
| **5ï¸âƒ£ Queries AnalÃ­ticas** | Spark SQL | Tablas Hive | `analytics_results.json` | ~4s |
| **6ï¸âƒ£ Reportes** | Python | Todos los resultados | Reportes MD/TXT/JSON | ~2s |

### **Stack TecnolÃ³gico**

<div align="center">

| Componente | TecnologÃ­a | PropÃ³sito |
|:----------:|:----------:|-----------|
| ğŸ”¥ **Procesamiento** | Apache Spark 3.5 | Motor de procesamiento distribuido |
| ğŸ **Lenguaje** | Python 3.9 + PySpark | Desarrollo del pipeline |
| ğŸ’¾ **Storage** | Parquet + Snappy | Formato columnar comprimido |
| ğŸ—„ï¸ **Metadatos** | Spark SQL (Hive) | GestiÃ³n de tablas y queries |
| ğŸ“Š **Analytics** | SQL + DataFrame API | AnÃ¡lisis de datos |
| ğŸ” **ValidaciÃ³n** | Custom Validators | Calidad de datos |
| ğŸ“ **Logging** | Python logging | Observabilidad |

</div>

### **SimulaciÃ³n del Ecosistema Cloudera**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PROYECTO LOCAL                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  data/raw/          â†’  HDFS /user/data/raw/                 â”‚
â”‚  data/processed/    â†’  HDFS /user/data/processed/           â”‚
â”‚  Spark local[*]     â†’  YARN cluster                         â”‚
â”‚  Spark SQL          â†’  Hive/Impala                          â”‚
â”‚  Parquet files      â†’  HDFS blocks                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **CaracterÃ­sticas de Escalabilidad**

âœ… **Particionado inteligente**: Datos divididos por aÃ±o/mes/dÃ­a  
âœ… **Formato columnar**: Parquet reduce I/O hasta 10x vs CSV  
âœ… **CompresiÃ³n Snappy**: Balance perfecto entre velocidad y tamaÃ±o  
âœ… **ConfiguraciÃ³n adaptativa**: Spark ajusta automÃ¡ticamente las particiones  
âœ… **Window Functions**: Procesamiento eficiente por ventanas  
âœ… **Predicate Pushdown**: Solo lee datos necesarios  

### **De Local a ProducciÃ³n**

| Aspecto | Local (Desarrollo) | Cloudera (ProducciÃ³n) |
|---------|-------------------|----------------------|
| **Storage** | Carpetas locales | HDFS distribuido |
| **Compute** | `local[*]` | YARN cluster |
| **Scheduler** | Manual | Airflow/Oozie |
| **Monitoring** | Logs locales | Cloudera Manager |
| **Security** | Sin autenticaciÃ³n | Ranger + Knox |
| **Metadata** | Spark SQL | Hive Metastore |

ğŸ¤ Casos de Uso
Este proyecto demuestra capacidades aplicables a:

Sector Bancario: DetecciÃ³n de fraude en tiempo real
E-commerce: AnÃ¡lisis de comportamiento de compra
Telecomunicaciones: Procesamiento de logs de red
IoT: AnÃ¡lisis de eventos de sensores
Marketing: SegmentaciÃ³n de clientes


ğŸ“– DocumentaciÃ³n Adicional

GuÃ­a de Desarrollo (prÃ³ximamente)
Arquitectura Detallada (prÃ³ximamente)
Preguntas Frecuentes (prÃ³ximamente)


ğŸ‘¤ Autor
Jhon Limones
MLOps Engineer | DevOps Specialist | Data Engineer

ğŸ“§ Email: [jhonlimones.developer@gmailcom]
ğŸ’¼ LinkedIn: [https://www.linkedin.com/in/jhon-limones-992b7b331/]
ğŸ™ GitHub: https://github.com/jhonlimones


ğŸ“„ Licencia
Este proyecto estÃ¡ bajo la Licencia MIT - ver el archivo LICENSE para mÃ¡s detalles.

ğŸ™ Agradecimientos
Proyecto desarrollado como demostraciÃ³n tÃ©cnica para la posiciÃ³n de Cloudera Data Engineer.
FormaciÃ³n base: Analista de Datos Big Data (120h) - Cloudera - Academia PUE DATA

â­ Si te resultÃ³ Ãºtil
Si este proyecto te ayudÃ³, considera darle una â­ en GitHub!

Desarrollado con â¤ï¸ para el ecosistema Cloudera